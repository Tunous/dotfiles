#!/usr/bin/python
# Script to randomly set background from wallpapers subreddit and imgur.
# Schedule with Cron: Run "crontab -e" then add an entry such as 
#        "*/30 * * * * /script/location"

# Usage: wallpaper --random   Randomly select rubreddit to download image from
# Usage: wallpaper --reddit   Pick random image from reddit
# Usage: wallpapwr --imgur    Pick random image from imgur

import os, sys, argparse, random, shutil, subprocess, requests

# Settings
client_id = 'a2994972b62d932' # Imgur required client-id
headers = {'User-Agent': 'n00b wallpaper bot v0.4',
       'Autorization': 'Client-ID ' + client_id}

links = ['http://www.reddit.com/r/wallpapers/.json',
          'http://www.reddit.com/r/wallpaper/.json',
          'https://imgur.com/r/wallpapers.json']

img_file = os.path.join(os.path.expanduser('~'), 'Dropbox', 'Images', 'wallpaper')

url_prefix = 'https://i.imgur.com/'
temp_suffix = '_temp'
img_exts = ['jpg','png']
hide_over_18 = True
# End Settings

def getimg(post):
    return post['data']['url']

def check_ext(img_url):
    for ext in img_exts:
        if img_url.endswith(ext):
            return True
    return False

def not_over_18(post):
    return not post['data']['over_18']

def correct_dimensions(post):
    title = post['data']['title']
    if "1920x1080" not in title:
        return False
    return True

def download_file(url, local_file):
    r = requests.get(url, stream=True, headers=headers)

    with open(local_file, 'wb') as fd:
        for chunk in r.iter_content(chunk_size = 1024):
            fd.write(chunk)

    r.raise_for_status() # If error downloading (404 etc) this will cause an exception
    shutil.move(local_file, img_file)
    subprocess.call(["feh", "--bg-fill", img_file])
    return True

def imgur(json_obj):
    posts = json_obj['data']
    looking = True
    finding = 5 # Will try to find up to this many images that satisfy hide_over_18 requirement

    while(looking and finding > 0):
        rand_url_pos = random.randrange(0, len(posts))
        rand_ext = posts[rand_url_pos]['ext']
        rand_url = posts[rand_url_pos]['hash']
        nsfw = posts[rand_url_pos]['nsfw']
        if hide_over_18 and nsfw:
            finding -= 1
        else:
            looking = False

    download_file(url_prefix + rand_url + rand_ext, img_file + temp_suffix)
    return

def reddit(json_obj):
    img_urls = []
    posts = json_obj['data']['children']
    # posts = list(filter(correct_dimensions, posts))

    if hide_over_18:
        posts = list(filter(not_over_18, posts))

    img_urls += list(filter(check_ext, list(map(getimg, posts))))
    rand_url = img_urls[random.randrange(0, len(img_urls))]

    download_file(rand_url, img_file + temp_suffix)
    return

def parse_args():
    parser = argparse.ArgumentParser(description='Downloads random image from reddit or imgur and sets it as wallpaper.')

    parser.add_argument('--imgur', help='Downloads a random image from imgur only.', action="store_true")
    parser.add_argument('--reddit', help='Downloads a random image from reddit only.', action="store_true")
    parser.add_argument('--random', help='Downloads a random image from a random source.', action="store_true")
    args = parser.parse_args()

    if args.imgur:
        return 2
    elif args.reddit:
        return random.randrange(0, 1)
    elif args.random:
        return random.randrange(0, len(links))
    else:
        parser.print_usage()
        sys.exit(2)
    return


# Main
link_id = parse_args()
f = requests.get(links[link_id], headers=headers)
json_obj = f.json()

if link_id < 2:
    print('Downloading image from reddit.')
    reddit(json_obj)
elif link_id == 2:
    print('Downloading image from imgur.')
    imgur(json_obj)
else:
    print('Error in links array!')
